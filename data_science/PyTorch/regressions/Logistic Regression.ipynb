{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1, weight=0.05578, loss=0.321095347404480\n",
      "epoch=51, weight=-0.01545, loss=0.138198614120483\n",
      "epoch=101, weight=-0.05084, loss=0.094870850443840\n",
      "epoch=151, weight=-0.07374, loss=0.077183559536934\n",
      "epoch=201, weight=-0.09074, loss=0.067363113164902\n",
      "epoch=251, weight=-0.10429, loss=0.060972627252340\n",
      "epoch=301, weight=-0.11559, loss=0.056403946131468\n",
      "epoch=351, weight=-0.12527, loss=0.052931535989046\n",
      "epoch=401, weight=-0.13376, loss=0.050177294760942\n",
      "epoch=451, weight=-0.14131, loss=0.047923214733601\n",
      "\n",
      "accuracy=96.49123%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split   # Split arrays or matrices into random train and test subsets\n",
    "from sklearn.preprocessing import StandardScaler       # Scaling data (calculating the standard score)\n",
    "\n",
    "# Loading 'breast cancer' dataset in iris variable\n",
    "bc = datasets.load_breast_cancer()\n",
    "\n",
    "# Initializing breast cancer data(excludes target column) and target column into variables\n",
    "# x contains all data(excluding target column)\n",
    "# y contains target column\n",
    "x, y = bc['data'], bc['target']\n",
    "\n",
    "n_samples, n_features = x.shape\n",
    "\n",
    "# train_test_split creates random data for training and testing and split both\n",
    "# number of samples will be always equal in both training and testing data\n",
    "# x_train will get 80% rows with all columns(excluding target column); test_size is 0.2 which means 20% data is for test(x_test)\n",
    "# y_train will get 80% rows of target column; test_size is 0.2 means 20% data is for test(y_test)\n",
    "# random_state: Controls the shuffling applied to the data before applying the split.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "# StandardScalar calculates the standard score\n",
    "# The standard score of a sample x is calculated as: z = (x - μ) / σ\n",
    "# where μ (mean or avg) = ( Σ x ) / n ; σ = √[{(Σx - μ)**2}/n]\n",
    "sc = StandardScaler()\n",
    "\n",
    "# sc.fit_transform(data) calculates the value of each parameter and applies to the dataset\n",
    "x_train = sc.fit_transform(x_train)\n",
    "\n",
    "# sc.transform(data) applies the values of the parameters on the actual data \n",
    "# only transform() must  be applied on test dataset because it has to learn calculatation(how to map one input space to another) \n",
    "# from training dataset thus it would be able to apply same operation on unseen data\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "# Convert numpy arrays to torch tensors as well as mention datatype\n",
    "x_train = torch.tensor(x_train.astype(np.float32))\n",
    "x_test = torch.tensor(x_test.astype(np.float32))\n",
    "y_train = torch.tensor(y_train.astype(np.float32))\n",
    "y_test = torch.tensor(y_test.astype(np.float32))\n",
    "\n",
    "# Changing the shape of tensor\n",
    "y_train = y_train.view(y_train.shape[0],1)\n",
    "y_test = y_test.view(y_test.shape[0],1)\n",
    "\n",
    "\n",
    "# manual class and function for Logistic Regression\n",
    "class LogisticRegress(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_input):\n",
    "        super(LogisticRegress,self).__init__()\n",
    "        self.a = nn.Linear(n_input, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.a(x)) #clamp(min=0, max=1)\n",
    "        return y_pred\n",
    "    \n",
    "\n",
    "# Logistic regression model\n",
    "model = LogisticRegress(n_features)\n",
    "\n",
    "\n",
    "learning_rate = 1e-2\n",
    "epoch = 500\n",
    "\n",
    "# Loss and optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "\n",
    "# Train the model\n",
    "for i in range(epoch):\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(x_train)\n",
    "    ls = loss(output,y_train)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    ls.backward()\n",
    "    optimizer.step()\n",
    "    if i%50==0:\n",
    "        [w,b] = model.parameters()\n",
    "        print(f\"epoch={i+1}, weight={w[0][0]:.5f}, loss={ls:.15f}\")\n",
    "\n",
    "        \n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "# with torch.no_grad() temporarily set all the requires_grad flag to false\n",
    "with torch.no_grad():\n",
    "    pred = model(x_test).round()\n",
    "    acc  = 100 * pred.eq(y_test).sum() / float(y_test.shape[0])\n",
    "              \n",
    "    print(f'\\naccuracy={acc:.5f}%')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
