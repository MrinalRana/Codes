{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST data contains images of hand written digits 0 to 9; each image size is (28 x 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "# torchvision library is part of the PyTorch project, consists of popular datasets, model architectures, and common image transformations for computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If GPU is available operations will be performed on GPU otherwise CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the data and converting to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root=\"/path\" defines where data should go; in this case it will go in default directory(for default we also could just use \"\" without writing root=)\n",
    "# train=True means to train the data\n",
    "# download=True to download the data; once downloaded it won't download again\n",
    "# transform=transforms.Compose([transforms.ToTensor()]) converting data into tensor\n",
    "train_data = datasets.MNIST(root=\"MNIST_DATA\", train=True, download=True, \n",
    "                       transform=transforms.Compose([transforms.ToTensor()])) \n",
    "\n",
    "test_data = datasets.MNIST(root=\"MNIST_DATA\", train=False, download=False, \n",
    "                      transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating batches of data to pass in training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All datasets are subclasses of torch.utils.data.Dataset(represents a Python iterable over a dataset) i.e, they have __getitem__ and __len__ methods implemented. Hence, they can all be \n",
    "# passed to a torch.utils.data.DataLoader which can load multiple samples parallelly using torch.multiprocessing workers. \n",
    "# If running on Windows and you get a BrokenPipeError, try setting the num_worker of torch.utils.data.DataLoader() to 0.\n",
    "# DataLoader: Takes any Dataset and creates an iterator which returns batches of data\n",
    "# batch_size represents the size of samples which we are going to feed in the model; an arbitrary number\n",
    "# shuffle=True so data can be trained with different items\n",
    "trainset = torch.utils.data.DataLoader(dataset=train_data, batch_size=10, shuffle=True)\n",
    "\n",
    "testset = torch.utils.data.DataLoader(test_data, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To see how first batch of data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n",
      "tensor(6)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Method 1:\n",
    "\n",
    "# To check single element\n",
    "\n",
    "# for data in trainset:\n",
    "#     #print(data)\n",
    "#     break\n",
    "\n",
    "# x, y = data[0][0], data[1][0]\n",
    "# print(y)\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(x[0])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# To check multiple elements\n",
    "for data in trainset:\n",
    "    for i in range(6):\n",
    "        x, y = data[0][i], data[1][i]\n",
    "        print(y)\n",
    "        plt.subplot(2,3,i+1)\n",
    "        plt.imshow(x[0])\n",
    "    break\n",
    "plt.show()\n",
    "# for data in trainset:\n",
    "#     for i in range(6):\n",
    "#         x, y = data\n",
    "#         plt.subplot(2,3, i+1)\n",
    "#         plt.imshow(x[i][0])\n",
    "#         print(y[i])\n",
    "#     break\n",
    "# plt.show()\n",
    "\n",
    "# Method 2:\n",
    "\n",
    "# first_batch = iter(trainset)\n",
    "# images, labels = first_batch.next()\n",
    "# print(images.shape, labels.shape)\n",
    "\n",
    "# for i in range(10):\n",
    "#     plt.subplot(2,5,i+1)\n",
    "#     plt.imshow(images[i][0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look on data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "key = 0, count = 5923, percent = 9.87%\n",
      "key = 1, count = 6742, percent = 11.24%\n",
      "key = 2, count = 5958, percent = 9.93%\n",
      "key = 3, count = 6131, percent = 10.22%\n",
      "key = 4, count = 5842, percent = 9.74%\n",
      "key = 5, count = 5421, percent = 9.04%\n",
      "key = 6, count = 5918, percent = 9.86%\n",
      "key = 7, count = 6265, percent = 10.44%\n",
      "key = 8, count = 5851, percent = 9.75%\n",
      "key = 9, count = 5949, percent = 9.91%\n"
     ]
    }
   ],
   "source": [
    "# Having a look on data how it has been distributed; if not properly distributed equally then have to balance it otherwise the weights are going to stuck on a point \n",
    "# and loss can't be decreased from a certain value\n",
    "\n",
    "total_elements = 0\n",
    "digits_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0, }\n",
    "\n",
    "for data in trainset:\n",
    "    x, y = data\n",
    "    for i in y:\n",
    "        digits_dict[int(i)] += 1\n",
    "        total_elements += 1\n",
    "        \n",
    "print(total_elements)\n",
    "print(digits_dict)\n",
    "\n",
    "for i in digits_dict:\n",
    "    print(f\"key = {i}, count = {digits_dict[i]}, percent = {round(100*digits_dict[i]/total_elements,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functional: a module(usually imported into the F namespace by convention) which contains activation functions, loss functions, etc, \n",
    "# as well as non-stateful versions of layers such as convolutional and linear layers\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Module: creates a callable which behaves like a function, but can also contain state(such as neural net layer weights). \n",
    "# It knows what Parameter (s) it contains and can zero all their gradients, loop \n",
    "class Nnet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 64)     # input= 784 => 28*28; hidden layer=64 (arbitrary number) as output\n",
    "        self.fc2 = nn.Linear(64, 64)      # fc1 output was 64 so fc2 input is 64; again second hidden layer=64 (arbitrary number)\n",
    "        self.fc3 = nn.Linear(64, 64)      # fc2 output was 64 so fc3 input is 64; again second hidden layer=64 (arbitrary number)\n",
    "        self.fc4 = nn.Linear(64, 10)      # fc3 output was 64 so fc4 input is 64; output is 10 because data has 0-9 digits\n",
    "        \n",
    "    def forward(self, x):                 # feed forward method\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "net = Nnet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1/3, step=1000/6000, loss=0.154947131872177\n",
      "epoch=1/3, step=2000/6000, loss=0.069240890443325\n",
      "epoch=1/3, step=3000/6000, loss=0.101538620889187\n",
      "epoch=1/3, step=4000/6000, loss=0.122869953513145\n",
      "epoch=1/3, step=5000/6000, loss=0.058587957173586\n",
      "epoch=1/3, step=6000/6000, loss=0.728203237056732\n",
      "epoch=2/3, step=1000/6000, loss=0.218361169099808\n",
      "epoch=2/3, step=2000/6000, loss=0.078737646341324\n",
      "epoch=2/3, step=3000/6000, loss=0.055690623819828\n",
      "epoch=2/3, step=4000/6000, loss=0.262235730886459\n",
      "epoch=2/3, step=5000/6000, loss=0.043340459465981\n",
      "epoch=2/3, step=6000/6000, loss=0.225408434867859\n",
      "epoch=3/3, step=1000/6000, loss=0.010230599902570\n",
      "epoch=3/3, step=2000/6000, loss=0.025454849004745\n",
      "epoch=3/3, step=3000/6000, loss=0.049931813031435\n",
      "epoch=3/3, step=4000/6000, loss=0.477973788976669\n",
      "epoch=3/3, step=5000/6000, loss=0.009507542476058\n",
      "epoch=3/3, step=6000/6000, loss=0.007160594221205\n"
     ]
    }
   ],
   "source": [
    "# torch.optim: Contains optimizers such as SGD, which update the weights of Parameter during the backward step\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "EPOCH = 3         # going to make 3 whole passes through entire dataset\n",
    "one_epoch_steps = len(trainset)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for idx, data in enumerate(trainset):\n",
    "        x, y = data\n",
    "        x = x.view(-1,28*28).to(device)\n",
    "        y = y.to(device)\n",
    "        pred_out = net(x)   # -1 is used to represent whatever batch size is\n",
    "        loss = F.nll_loss(pred_out, y)\n",
    "        # optim.zero_grad() resets the gradient to 0 and we need to call it before computing the gradient for the next minibatch\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (idx)%1000==999:\n",
    "            print(f'epoch={epoch+1}/{EPOCH}, step={idx+1}/{one_epoch_steps}, loss={loss.item():.15f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 96.9\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        x, y = data\n",
    "        x = x.view(-1,28*28).to(device)\n",
    "        y = y.to(device)\n",
    "        output = net(x)\n",
    "        for idx, i in enumerate(output):\n",
    "            # Returns the indices of the maximum value of all elements in the input tensor\n",
    "            # torch.argmax() returns the second value of torch.max()\n",
    "            # value, index = torch.max(output, 1)\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                n_correct += 1\n",
    "            total_samples += 1\n",
    "accuracy = 100 * n_correct / total_samples\n",
    "print(f'Accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying the value with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n",
      "tensor(8)\n",
      "tensor(9)\n",
      "tensor(0)\n",
      "tensor(1)\n",
      "tensor(2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(6):\n",
    "    print(torch.argmax(net(x[i].view(-1,784))[0]))\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(x[i].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For official documentation click **[here](https://pytorch.org/tutorials/beginner/nn_tutorial.html)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using tensorboard displaying data on images tab, model on graph tab and accuray & loss on scalar tab; code used for tensorborad is uncommented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install TensorBoard running command in cmd (pip install tensorboard) and start it from cmd like jupyter notebook (tensorboard --logdir=/path/directory_name), these utilities let you log PyTorch models and metrics into a directory for visualization within the TensorBoard UI. Scalars, images, histograms, graphs, and embedding visualizations are all supported for PyTorch models and tensors as well as Caffe2 nets and blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7564), started 5:26:44 ago. (Use '!kill 7564' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3194b6ac309553c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3194b6ac309553c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1/3, step=100/600, loss=0.547341048717499\n",
      "epoch=1/3, step=200/600, loss=0.439677387475967\n",
      "epoch=1/3, step=300/600, loss=0.301797777414322\n",
      "epoch=1/3, step=400/600, loss=0.230129033327103\n",
      "epoch=1/3, step=500/600, loss=0.304620951414108\n",
      "epoch=1/3, step=600/600, loss=0.260904073715210\n",
      "epoch=2/3, step=100/600, loss=0.204097837209702\n",
      "epoch=2/3, step=200/600, loss=0.111001320183277\n",
      "epoch=2/3, step=300/600, loss=0.146681696176529\n",
      "epoch=2/3, step=400/600, loss=0.154352992773056\n",
      "epoch=2/3, step=500/600, loss=0.380173087120056\n",
      "epoch=2/3, step=600/600, loss=0.164586007595062\n",
      "epoch=3/3, step=100/600, loss=0.106613472104073\n",
      "epoch=3/3, step=200/600, loss=0.218865469098091\n",
      "epoch=3/3, step=300/600, loss=0.191051274538040\n",
      "epoch=3/3, step=400/600, loss=0.073826529085636\n",
      "epoch=3/3, step=500/600, loss=0.257843017578125\n",
      "epoch=3/3, step=600/600, loss=0.098212480545044\n"
     ]
    }
   ],
   "source": [
    "# Uncomment all the code before running\n",
    "\n",
    "# import torch\n",
    "# import torchvision\n",
    "# from torchvision import datasets, transforms\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "## The SummaryWriter class is the main entry to log data for consumption and visualization by TensorBoard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "## tensorboard extension needs to be loaded(only once) before running it through jupyter notebook(alternative way of cmd)\n",
    "%load_ext tensorboard   \n",
    "\n",
    "## Refresh the tensorboard from the given button to have the changes appear\n",
    "## launching tensor board in jupyter notebook alternative way of cmd\n",
    "%tensorboard --logdir=runs\n",
    "\n",
    "\n",
    "## writer will output to ./runs/ directory by default, this is log directory\n",
    "# writer = SummaryWriter(\"runs/mnist_logs\")\n",
    "\n",
    "# train_data = datasets.MNIST(root=\"MNIST_DATA\", train=True, download=True, \n",
    "#                        transform=transforms.Compose([transforms.ToTensor()])) \n",
    "\n",
    "# test_data = datasets.MNIST(root=\"MNIST_DATA\", train=False, download=False, \n",
    "#                       transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "\n",
    "# trainset = torch.utils.data.DataLoader(dataset=train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# testset = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
    "\n",
    "\n",
    "## for data in trainset:\n",
    "##     x, y = data\n",
    "##     break\n",
    "## another way\n",
    "data = iter(trainset)\n",
    "x, y = data.next()\n",
    "\n",
    "## making a grid with all images to display\n",
    "img_grid = torchvision.utils.make_grid(x)\n",
    "\n",
    "## adding the grid to as an image to tensorboard\n",
    "writer.add_image('MNIST Images', img_grid)\n",
    "\n",
    "## clearing the writer\n",
    "writer.close()\n",
    "\n",
    "    \n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class Nnet(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.fc1 = nn.Linear(784, 64)     \n",
    "#         self.fc2 = nn.Linear(64, 64)      \n",
    "#         self.fc3 = nn.Linear(64, 64)      \n",
    "#         self.fc4 = nn.Linear(64, 10)      \n",
    "        \n",
    "#     def forward(self, x):                 \n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = F.relu(self.fc3(x))\n",
    "#         x = self.fc4(x)\n",
    "#         return F.log_softmax(x, dim=1)\n",
    "    \n",
    "# model = Nnet()\n",
    "\n",
    "# import torch.optim as optim\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "## adding graph to see the models with input, linear layer, activation function, output  flow chart\n",
    "writer.add_graph(model, x.view(-1,28*28))\n",
    "writer.close()\n",
    "\n",
    "# EPOCH = 3\n",
    "\n",
    "catch_loss = 0\n",
    "catch_accuracy = 0\n",
    "\n",
    "# for epoch in range(EPOCH):\n",
    "#     for idx, data in enumerate(trainset):\n",
    "#         x, y = data\n",
    "#         x = x.view(-1,28*28)\n",
    "        \n",
    "#         pred_out = model(x)  \n",
    "#         loss = F.nll_loss(pred_out, y)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "        ## capture the loss\n",
    "        catch_loss += loss.item() \n",
    "        \n",
    "        ## measuring the accuracy \n",
    "        catch_accuracy += (torch.argmax(pred_out, 1) == y).sum().item()\n",
    "        \n",
    "#         if (idx)%100==99:\n",
    "#             print(f'epoch={epoch+1}/{EPOCH}, step={idx+1}/{len(trainset)}, loss={loss.item():.15f}')\n",
    "            \n",
    "            ## adding scalar to see the loss and accuracy on tensorboard\n",
    "            writer.add_scalar('training loss', catch_loss/100, epoch * len(trainset) + idx)\n",
    "            writer.add_scalar('training accuracy', catch_accuracy/100, epoch * len(trainset) + idx)\n",
    "            \n",
    "            ## reseting the variable to catch the loss for another batch\n",
    "            catch_loss = 0\n",
    "            catch_accuracy = 0\n",
    "            \n",
    "            ## clearing the writer\n",
    "            writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TensorBoard Scalar](png/scalar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TensorBoard Images](png/data_batch.png \"Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TensorBoard Graph](png/model.png \"Graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.utils.tensorboard **[documentation](https://pytorch.org/docs/stable/tensorboard.html)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
